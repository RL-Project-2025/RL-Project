{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adaf1248-4e8c-4f53-b9f2-bf7e1088f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/miniforge3/envs/rl/lib/python3.10/site-packages/wntr/epanet/toolkit.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gym4real\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gym4real.envs.wds.utils import parameter_generator\n",
    "from gym4real.envs.wds.reward_scaling_wrapper import RewardScalingWrapper\n",
    "import wntr\n",
    "import wntr.sim\n",
    "from DQN import DQN_Implementation, Double_DQN_Implementation\n",
    "from gym4real.envs.wds.Normalise import NormaliseObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4232393-9fd0-4df2-ac92-a11b59814831",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(os.getcwd(), \"gym4real\", \"envs\", \"wds\", \"world_anytown.yaml\")\n",
    "\n",
    "base_params = parameter_generator(\n",
    "    hydraulic_step=3600,\n",
    "    duration=604800,\n",
    "    seed=42,\n",
    "    world_options=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcaa408-f00f-4b3d-98a3-1e16740f9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment using SMA\n",
    "base_params['demand_moving_average'] = True  # Turn on SMA \n",
    "base_params['demand_exp_moving_average'] = False  # Turn off EMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd21602b-e29f-4f3e-9f40-13049fe8d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    env = gym.make('gym4real/wds-v0', settings=base_params)\n",
    "    env = RewardScalingWrapper(env)\n",
    "    env = NormaliseObservation(env)\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f2ddb0-5a53-4a52-9b65-67d3aec493cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/miniforge3/envs/rl/lib/python3.10/site-packages/gymnasium/spaces/box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/Users/kavish/miniforge3/envs/rl/lib/python3.10/site-packages/gymnasium/spaces/box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200000 steps\n",
      "Resetting the environment...\n",
      "Step: 191 | Episode Reward: 138.400 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 405 | Episode Reward: 136.426 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 595 | Episode Reward: 144.094 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 797 | Episode Reward: 137.155 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1002 | Episode Reward: 139.300 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1205 | Episode Reward: 135.185 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1403 | Episode Reward: 142.329 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1595 | Episode Reward: 145.862 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1806 | Episode Reward: 136.360 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1999 | Episode Reward: 122.239 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2200 | Episode Reward: 138.053 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2393 | Episode Reward: 135.362 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2599 | Episode Reward: 138.330 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2791 | Episode Reward: 135.165 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2995 | Episode Reward: 130.952 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3205 | Episode Reward: 139.549 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3392 | Episode Reward: 141.494 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3588 | Episode Reward: 143.420 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3776 | Episode Reward: 145.140 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3976 | Episode Reward: 132.877 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4173 | Episode Reward: 132.669 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4359 | Episode Reward: 142.609 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4563 | Episode Reward: 137.729 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4753 | Episode Reward: 142.755 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4941 | Episode Reward: 139.959 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5136 | Episode Reward: 145.237 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5334 | Episode Reward: 139.637 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5562 | Episode Reward: 144.249 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5808 | Episode Reward: 137.158 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6049 | Episode Reward: 137.117 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6247 | Episode Reward: 142.662 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6431 | Episode Reward: 143.073 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6616 | Episode Reward: 136.345 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6824 | Episode Reward: 139.157 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7020 | Episode Reward: 137.766 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7219 | Episode Reward: 144.107 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7467 | Episode Reward: 138.037 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7656 | Episode Reward: 131.170 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7833 | Episode Reward: 142.664 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8040 | Episode Reward: 140.903 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8229 | Episode Reward: 142.709 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8422 | Episode Reward: 137.551 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8661 | Episode Reward: 136.641 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8865 | Episode Reward: 139.218 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9069 | Episode Reward: 138.349 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9265 | Episode Reward: 139.941 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9457 | Episode Reward: 140.707 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9652 | Episode Reward: 142.986 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9858 | Episode Reward: 135.312 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10073 | Episode Reward: 138.483 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10277 | Episode Reward: 134.293 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10470 | Episode Reward: 138.990 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10721 | Episode Reward: 136.493 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10926 | Episode Reward: 145.083 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11128 | Episode Reward: 136.220 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11372 | Episode Reward: 141.251 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11557 | Episode Reward: 141.507 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11789 | Episode Reward: 143.674 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11990 | Episode Reward: 142.584 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12181 | Episode Reward: 136.892 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12384 | Episode Reward: 135.948 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12586 | Episode Reward: 118.666 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12790 | Episode Reward: 123.717 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13030 | Episode Reward: 135.038 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13254 | Episode Reward: 135.371 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13474 | Episode Reward: 136.909 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13656 | Episode Reward: 144.960 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13849 | Episode Reward: 144.005 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14050 | Episode Reward: 127.928 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14254 | Episode Reward: 137.474 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14474 | Episode Reward: 137.438 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14661 | Episode Reward: 147.991 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14862 | Episode Reward: 136.349 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15069 | Episode Reward: 135.177 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15260 | Episode Reward: 142.528 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15440 | Episode Reward: 144.572 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15642 | Episode Reward: 143.041 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15841 | Episode Reward: 144.519 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16044 | Episode Reward: 130.745 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16242 | Episode Reward: 141.646 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16480 | Episode Reward: 138.547 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16677 | Episode Reward: 144.450 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16884 | Episode Reward: 138.931 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17088 | Episode Reward: 139.400 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17295 | Episode Reward: 137.851 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17487 | Episode Reward: 140.754 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17686 | Episode Reward: 140.202 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17874 | Episode Reward: 137.083 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18076 | Episode Reward: 130.041 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18277 | Episode Reward: 137.377 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18465 | Episode Reward: 141.979 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18664 | Episode Reward: 142.063 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18845 | Episode Reward: 145.395 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19045 | Episode Reward: 138.222 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19237 | Episode Reward: 116.536 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19438 | Episode Reward: 138.568 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19634 | Episode Reward: 134.976 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19841 | Episode Reward: 130.456 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20036 | Episode Reward: 141.366 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20240 | Episode Reward: 138.970 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20442 | Episode Reward: 121.258 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20637 | Episode Reward: 142.445 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20832 | Episode Reward: 141.973 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21033 | Episode Reward: 135.558 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21273 | Episode Reward: 140.376 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21522 | Episode Reward: 131.776 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21723 | Episode Reward: 141.481 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21929 | Episode Reward: 132.561 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22114 | Episode Reward: 145.249 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22309 | Episode Reward: 139.644 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22500 | Episode Reward: 145.491 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22711 | Episode Reward: 136.353 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22926 | Episode Reward: 136.731 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23134 | Episode Reward: 136.273 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23334 | Episode Reward: 135.798 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23567 | Episode Reward: 147.463 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23775 | Episode Reward: 137.171 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23992 | Episode Reward: 136.919 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24190 | Episode Reward: 140.420 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24386 | Episode Reward: 144.347 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24572 | Episode Reward: 144.450 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24810 | Episode Reward: 136.556 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25003 | Episode Reward: 146.069 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25212 | Episode Reward: 137.722 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25403 | Episode Reward: 141.687 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25591 | Episode Reward: 138.798 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25774 | Episode Reward: 147.081 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25965 | Episode Reward: 142.712 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26204 | Episode Reward: 146.485 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26404 | Episode Reward: 122.255 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26612 | Episode Reward: 131.480 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26803 | Episode Reward: 144.890 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26995 | Episode Reward: 137.805 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27204 | Episode Reward: 134.122 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27413 | Episode Reward: 143.296 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27601 | Episode Reward: 145.413 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27794 | Episode Reward: 146.883 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27981 | Episode Reward: 145.225 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28183 | Episode Reward: 139.640 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28374 | Episode Reward: 144.484 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 28616 | Episode Reward: 120.822 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28815 | Episode Reward: 138.817 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29013 | Episode Reward: 140.071 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29214 | Episode Reward: 137.798 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29457 | Episode Reward: 141.129 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29661 | Episode Reward: 132.127 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29851 | Episode Reward: 139.865 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30033 | Episode Reward: 143.988 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30234 | Episode Reward: 137.920 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30431 | Episode Reward: 144.293 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30626 | Episode Reward: 139.467 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30868 | Episode Reward: 140.698 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31079 | Episode Reward: 139.298 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31287 | Episode Reward: 131.768 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31489 | Episode Reward: 141.064 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31689 | Episode Reward: 145.368 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31876 | Episode Reward: 143.720 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32060 | Episode Reward: 142.162 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32260 | Episode Reward: 134.268 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32511 | Episode Reward: 144.330 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32709 | Episode Reward: 134.378 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32892 | Episode Reward: 144.343 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33096 | Episode Reward: 141.685 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33323 | Episode Reward: 144.534 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33516 | Episode Reward: 138.372 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33721 | Episode Reward: 140.686 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33956 | Episode Reward: 144.168 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34148 | Episode Reward: 141.657 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34353 | Episode Reward: 135.213 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34546 | Episode Reward: 126.140 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34738 | Episode Reward: 143.749 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34932 | Episode Reward: 137.377 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35124 | Episode Reward: 134.995 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35325 | Episode Reward: 134.597 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35527 | Episode Reward: 141.737 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35733 | Episode Reward: 136.834 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35932 | Episode Reward: 137.187 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36129 | Episode Reward: 142.705 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36325 | Episode Reward: 144.420 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36522 | Episode Reward: 135.995 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36713 | Episode Reward: 144.469 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36908 | Episode Reward: 137.230 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: System may be hydraulically unstable.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 37146 | Episode Reward: 141.331 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37334 | Episode Reward: 115.489 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37545 | Episode Reward: 146.964 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37744 | Episode Reward: 138.517 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37948 | Episode Reward: 142.136 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38144 | Episode Reward: 141.028 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38332 | Episode Reward: 137.914 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38534 | Episode Reward: 140.400 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38735 | Episode Reward: 138.183 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38935 | Episode Reward: 136.123 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39127 | Episode Reward: 141.920 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39318 | Episode Reward: 122.524 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39561 | Episode Reward: 127.728 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39743 | Episode Reward: 140.927 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39948 | Episode Reward: 130.756 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40138 | Episode Reward: 141.011 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40339 | Episode Reward: 137.993 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40539 | Episode Reward: 133.684 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40723 | Episode Reward: 149.165 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 40960 | Episode Reward: 131.325 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41159 | Episode Reward: 143.337 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41358 | Episode Reward: 144.005 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41543 | Episode Reward: 124.730 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41738 | Episode Reward: 136.828 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41948 | Episode Reward: 136.585 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42194 | Episode Reward: 139.402 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42386 | Episode Reward: 144.362 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42584 | Episode Reward: 147.530 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42792 | Episode Reward: 141.378 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42991 | Episode Reward: 142.475 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43187 | Episode Reward: 142.097 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43392 | Episode Reward: 139.427 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43591 | Episode Reward: 145.968 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43843 | Episode Reward: 136.918 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44045 | Episode Reward: 134.035 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44239 | Episode Reward: 145.118 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44485 | Episode Reward: 145.247 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44678 | Episode Reward: 142.060 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44890 | Episode Reward: 139.338 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45090 | Episode Reward: 142.574 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45330 | Episode Reward: 149.106 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45530 | Episode Reward: 134.367 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45723 | Episode Reward: 141.958 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45924 | Episode Reward: 119.698 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46108 | Episode Reward: 145.854 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46308 | Episode Reward: 142.770 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46508 | Episode Reward: 138.461 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46715 | Episode Reward: 139.827 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46907 | Episode Reward: 143.975 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47104 | Episode Reward: 146.483 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47291 | Episode Reward: 141.554 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47487 | Episode Reward: 142.322 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47684 | Episode Reward: 144.482 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47898 | Episode Reward: 129.892 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48087 | Episode Reward: 144.055 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48303 | Episode Reward: 137.912 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48491 | Episode Reward: 140.701 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48698 | Episode Reward: 138.522 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48895 | Episode Reward: 139.287 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49093 | Episode Reward: 136.882 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49344 | Episode Reward: 136.526 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49543 | Episode Reward: 136.035 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49735 | Episode Reward: 142.490 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49924 | Episode Reward: 146.254 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50118 | Episode Reward: 144.976 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50304 | Episode Reward: 141.817 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50503 | Episode Reward: 135.438 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50705 | Episode Reward: 133.670 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50904 | Episode Reward: 116.309 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51148 | Episode Reward: 142.315 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51355 | Episode Reward: 137.481 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51561 | Episode Reward: 140.828 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51760 | Episode Reward: 139.373 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51987 | Episode Reward: 143.041 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52182 | Episode Reward: 144.277 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52378 | Episode Reward: 142.730 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52574 | Episode Reward: 139.244 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52761 | Episode Reward: 139.817 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52961 | Episode Reward: 140.551 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53162 | Episode Reward: 134.482 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53347 | Episode Reward: 140.634 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53547 | Episode Reward: 140.308 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53746 | Episode Reward: 144.566 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53944 | Episode Reward: 143.511 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54141 | Episode Reward: 135.831 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54332 | Episode Reward: 146.123 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54532 | Episode Reward: 136.344 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54728 | Episode Reward: 144.274 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54923 | Episode Reward: 140.670 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55118 | Episode Reward: 142.899 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55327 | Episode Reward: 134.207 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55527 | Episode Reward: 142.446 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55754 | Episode Reward: 145.900 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55965 | Episode Reward: 141.874 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56216 | Episode Reward: 131.047 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56422 | Episode Reward: 138.040 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56626 | Episode Reward: 139.593 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56874 | Episode Reward: 133.210 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57059 | Episode Reward: 138.083 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57255 | Episode Reward: 132.496 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57446 | Episode Reward: 142.075 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57630 | Episode Reward: 149.249 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57819 | Episode Reward: 144.105 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58003 | Episode Reward: 141.533 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58196 | Episode Reward: 139.702 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58397 | Episode Reward: 135.732 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58605 | Episode Reward: 142.918 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 58862 | Episode Reward: 133.801 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59059 | Episode Reward: 141.448 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59256 | Episode Reward: 135.557 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59478 | Episode Reward: 140.002 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59707 | Episode Reward: 142.744 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59918 | Episode Reward: 146.343 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60115 | Episode Reward: 143.830 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60355 | Episode Reward: 142.482 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60542 | Episode Reward: 145.373 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60743 | Episode Reward: 139.283 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60983 | Episode Reward: 144.049 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61171 | Episode Reward: 143.228 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61368 | Episode Reward: 133.443 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61558 | Episode Reward: 143.412 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61777 | Episode Reward: 148.252 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61971 | Episode Reward: 141.079 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62166 | Episode Reward: 142.479 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62356 | Episode Reward: 132.739 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62564 | Episode Reward: 137.562 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62765 | Episode Reward: 136.278 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62957 | Episode Reward: 137.295 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 63195 | Episode Reward: 126.881 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 63409 | Episode Reward: 139.799 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 63609 | Episode Reward: 140.701 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 63819 | Episode Reward: 135.248 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64017 | Episode Reward: 135.113 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64226 | Episode Reward: 139.826 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64411 | Episode Reward: 136.348 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64607 | Episode Reward: 142.453 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64806 | Episode Reward: 135.876 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65020 | Episode Reward: 137.762 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65237 | Episode Reward: 131.061 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65470 | Episode Reward: 127.771 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65706 | Episode Reward: 136.029 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65897 | Episode Reward: 142.566 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66079 | Episode Reward: 144.891 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66281 | Episode Reward: 142.472 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66480 | Episode Reward: 138.409 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66666 | Episode Reward: 141.951 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66845 | Episode Reward: 140.086 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67045 | Episode Reward: 139.577 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67247 | Episode Reward: 139.315 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67467 | Episode Reward: 141.942 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67711 | Episode Reward: 128.542 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67904 | Episode Reward: 144.491 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68101 | Episode Reward: 144.866 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68313 | Episode Reward: 143.453 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68517 | Episode Reward: 131.990 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68759 | Episode Reward: 146.978 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68953 | Episode Reward: 145.660 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69163 | Episode Reward: 146.267 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69416 | Episode Reward: 134.283 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69607 | Episode Reward: 135.282 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69810 | Episode Reward: 137.901 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70005 | Episode Reward: 141.524 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70239 | Episode Reward: 144.741 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70444 | Episode Reward: 145.003 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70636 | Episode Reward: 141.123 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70822 | Episode Reward: 142.608 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71015 | Episode Reward: 145.574 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71210 | Episode Reward: 134.584 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71399 | Episode Reward: 147.235 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71598 | Episode Reward: 137.106 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71839 | Episode Reward: 128.986 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72039 | Episode Reward: 138.169 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72225 | Episode Reward: 139.537 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72414 | Episode Reward: 147.228 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72616 | Episode Reward: 144.893 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72806 | Episode Reward: 144.793 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73045 | Episode Reward: 138.515 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73242 | Episode Reward: 145.852 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73420 | Episode Reward: 147.271 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73615 | Episode Reward: 143.961 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 73866 | Episode Reward: 123.177 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74061 | Episode Reward: 135.615 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74257 | Episode Reward: 145.723 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74450 | Episode Reward: 147.037 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74654 | Episode Reward: 135.013 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74861 | Episode Reward: 135.921 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75051 | Episode Reward: 135.427 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75237 | Episode Reward: 148.033 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75439 | Episode Reward: 136.765 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75640 | Episode Reward: 139.922 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75891 | Episode Reward: 139.501 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76086 | Episode Reward: 140.548 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76289 | Episode Reward: 137.079 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76477 | Episode Reward: 124.195 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76681 | Episode Reward: 138.215 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76875 | Episode Reward: 136.609 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77075 | Episode Reward: 141.743 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77270 | Episode Reward: 140.655 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77457 | Episode Reward: 139.374 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77648 | Episode Reward: 135.311 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77865 | Episode Reward: 134.829 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78070 | Episode Reward: 140.467 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78289 | Episode Reward: 136.605 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78478 | Episode Reward: 144.791 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78668 | Episode Reward: 133.539 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78866 | Episode Reward: 140.736 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79083 | Episode Reward: 135.844 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79275 | Episode Reward: 142.236 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79482 | Episode Reward: 139.277 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79679 | Episode Reward: 141.719 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79908 | Episode Reward: 142.969 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80097 | Episode Reward: 140.058 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80302 | Episode Reward: 131.532 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80544 | Episode Reward: 147.696 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80746 | Episode Reward: 142.867 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80951 | Episode Reward: 143.454 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81166 | Episode Reward: 131.585 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81375 | Episode Reward: 138.855 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81589 | Episode Reward: 126.293 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81782 | Episode Reward: 140.147 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81981 | Episode Reward: 136.122 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82173 | Episode Reward: 142.319 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82372 | Episode Reward: 137.932 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82567 | Episode Reward: 142.555 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82756 | Episode Reward: 133.648 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82952 | Episode Reward: 136.222 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83144 | Episode Reward: 146.109 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83352 | Episode Reward: 137.157 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83553 | Episode Reward: 124.475 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83756 | Episode Reward: 130.789 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83952 | Episode Reward: 138.921 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84196 | Episode Reward: 143.489 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84406 | Episode Reward: 140.803 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84597 | Episode Reward: 136.181 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84792 | Episode Reward: 141.807 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84987 | Episode Reward: 138.506 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85186 | Episode Reward: 142.609 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85396 | Episode Reward: 135.647 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85594 | Episode Reward: 138.619 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85800 | Episode Reward: 145.966 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85998 | Episode Reward: 141.997 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86191 | Episode Reward: 138.899 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86397 | Episode Reward: 137.600 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86581 | Episode Reward: 145.969 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86771 | Episode Reward: 141.494 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86973 | Episode Reward: 132.351 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87159 | Episode Reward: 144.357 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87355 | Episode Reward: 135.270 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87552 | Episode Reward: 131.449 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87742 | Episode Reward: 143.713 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87934 | Episode Reward: 136.053 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88137 | Episode Reward: 141.304 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88327 | Episode Reward: 137.655 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88534 | Episode Reward: 134.899 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88726 | Episode Reward: 138.048 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88910 | Episode Reward: 142.874 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89153 | Episode Reward: 145.224 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89385 | Episode Reward: 141.351 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89578 | Episode Reward: 136.730 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89786 | Episode Reward: 132.837 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89986 | Episode Reward: 135.766 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90178 | Episode Reward: 142.842 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90371 | Episode Reward: 139.614 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90578 | Episode Reward: 130.771 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90760 | Episode Reward: 138.552 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90954 | Episode Reward: 137.698 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91143 | Episode Reward: 143.003 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91341 | Episode Reward: 143.461 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91533 | Episode Reward: 146.374 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91715 | Episode Reward: 144.007 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91984 | Episode Reward: 140.211 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92182 | Episode Reward: 141.403 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92379 | Episode Reward: 136.619 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92572 | Episode Reward: 126.277 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92764 | Episode Reward: 136.157 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92958 | Episode Reward: 142.535 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93154 | Episode Reward: 147.694 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93389 | Episode Reward: 140.885 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93577 | Episode Reward: 124.679 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93786 | Episode Reward: 134.191 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93986 | Episode Reward: 135.398 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94184 | Episode Reward: 143.345 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94386 | Episode Reward: 140.890 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94597 | Episode Reward: 135.255 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94799 | Episode Reward: 143.620 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94999 | Episode Reward: 140.357 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95186 | Episode Reward: 140.801 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95429 | Episode Reward: 138.618 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95631 | Episode Reward: 119.549 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95832 | Episode Reward: 134.382 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96043 | Episode Reward: 135.670 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96247 | Episode Reward: 138.785 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96438 | Episode Reward: 139.459 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96630 | Episode Reward: 143.618 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96829 | Episode Reward: 135.372 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97070 | Episode Reward: 141.614 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97262 | Episode Reward: 143.811 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97455 | Episode Reward: 143.528 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97697 | Episode Reward: 144.176 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97898 | Episode Reward: 141.624 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98097 | Episode Reward: 141.126 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98298 | Episode Reward: 140.133 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98491 | Episode Reward: 138.058 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98690 | Episode Reward: 136.416 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98884 | Episode Reward: 142.439 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99074 | Episode Reward: 140.506 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99271 | Episode Reward: 142.655 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99467 | Episode Reward: 134.466 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99715 | Episode Reward: 142.758 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99921 | Episode Reward: 138.006 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100125 | Episode Reward: 139.685 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100329 | Episode Reward: 135.723 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100514 | Episode Reward: 141.024 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100766 | Episode Reward: 144.691 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100964 | Episode Reward: 138.282 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101160 | Episode Reward: 139.541 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101354 | Episode Reward: 143.521 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101557 | Episode Reward: 136.588 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101756 | Episode Reward: 143.286 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101948 | Episode Reward: 145.025 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102139 | Episode Reward: 123.733 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102330 | Episode Reward: 138.877 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102524 | Episode Reward: 138.407 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102727 | Episode Reward: 136.474 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102916 | Episode Reward: 140.916 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103109 | Episode Reward: 138.401 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103353 | Episode Reward: 134.466 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103541 | Episode Reward: 143.162 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103746 | Episode Reward: 143.719 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103941 | Episode Reward: 131.896 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104131 | Episode Reward: 126.189 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104319 | Episode Reward: 143.671 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104577 | Episode Reward: 139.939 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104787 | Episode Reward: 139.631 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104982 | Episode Reward: 140.546 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105177 | Episode Reward: 141.819 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105379 | Episode Reward: 139.899 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105578 | Episode Reward: 142.896 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105770 | Episode Reward: 142.876 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105958 | Episode Reward: 138.788 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106156 | Episode Reward: 140.747 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106355 | Episode Reward: 134.798 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106543 | Episode Reward: 142.600 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106739 | Episode Reward: 140.674 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106942 | Episode Reward: 144.525 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107142 | Episode Reward: 143.462 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107370 | Episode Reward: 135.090 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107623 | Episode Reward: 134.870 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107813 | Episode Reward: 141.810 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108003 | Episode Reward: 146.315 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108204 | Episode Reward: 137.937 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108398 | Episode Reward: 144.280 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108596 | Episode Reward: 138.390 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108792 | Episode Reward: 133.778 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108990 | Episode Reward: 143.870 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109210 | Episode Reward: 142.789 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109395 | Episode Reward: 142.682 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109661 | Episode Reward: 124.307 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109908 | Episode Reward: 129.134 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110097 | Episode Reward: 139.511 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110299 | Episode Reward: 128.644 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110493 | Episode Reward: 142.864 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110688 | Episode Reward: 143.485 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110887 | Episode Reward: 143.785 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111135 | Episode Reward: 136.155 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111339 | Episode Reward: 140.849 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111539 | Episode Reward: 139.977 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111739 | Episode Reward: 138.253 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111927 | Episode Reward: 143.773 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112117 | Episode Reward: 137.871 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112320 | Episode Reward: 140.516 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112517 | Episode Reward: 136.055 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112720 | Episode Reward: 140.528 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112931 | Episode Reward: 139.153 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113127 | Episode Reward: 141.273 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113326 | Episode Reward: 132.860 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113515 | Episode Reward: 140.462 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113745 | Episode Reward: 141.487 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113945 | Episode Reward: 145.689 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114132 | Episode Reward: 139.437 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114333 | Episode Reward: 141.149 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114538 | Episode Reward: 136.828 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114732 | Episode Reward: 140.069 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114938 | Episode Reward: 142.876 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115145 | Episode Reward: 137.553 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 115376 | Episode Reward: 133.203 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115576 | Episode Reward: 136.836 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115780 | Episode Reward: 142.934 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115971 | Episode Reward: 140.871 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116171 | Episode Reward: 142.280 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116369 | Episode Reward: 135.465 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116584 | Episode Reward: 140.940 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116798 | Episode Reward: 133.925 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116998 | Episode Reward: 146.835 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117180 | Episode Reward: 141.587 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117375 | Episode Reward: 145.281 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117573 | Episode Reward: 141.520 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117781 | Episode Reward: 135.900 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117981 | Episode Reward: 137.513 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118176 | Episode Reward: 132.423 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118359 | Episode Reward: 141.847 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118559 | Episode Reward: 145.130 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118763 | Episode Reward: 136.638 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118968 | Episode Reward: 134.457 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119153 | Episode Reward: 142.609 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119352 | Episode Reward: 140.953 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119595 | Episode Reward: 130.693 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119793 | Episode Reward: 137.090 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119978 | Episode Reward: 143.700 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120179 | Episode Reward: 135.109 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120378 | Episode Reward: 135.451 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120580 | Episode Reward: 141.378 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120776 | Episode Reward: 146.503 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121043 | Episode Reward: 134.302 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121230 | Episode Reward: 145.153 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121423 | Episode Reward: 146.290 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121627 | Episode Reward: 141.183 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121825 | Episode Reward: 135.900 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122016 | Episode Reward: 141.484 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122203 | Episode Reward: 144.816 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122454 | Episode Reward: 135.436 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122645 | Episode Reward: 141.272 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122861 | Episode Reward: 139.442 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123074 | Episode Reward: 141.110 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123272 | Episode Reward: 122.667 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123478 | Episode Reward: 140.803 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123678 | Episode Reward: 138.625 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123878 | Episode Reward: 137.636 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124078 | Episode Reward: 144.695 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124271 | Episode Reward: 140.067 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124474 | Episode Reward: 143.233 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124681 | Episode Reward: 137.112 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124895 | Episode Reward: 141.790 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125099 | Episode Reward: 140.086 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125300 | Episode Reward: 138.105 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125486 | Episode Reward: 141.893 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125699 | Episode Reward: 143.125 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125901 | Episode Reward: 134.391 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126113 | Episode Reward: 137.545 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126320 | Episode Reward: 130.407 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126513 | Episode Reward: 142.528 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126715 | Episode Reward: 145.557 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126909 | Episode Reward: 142.797 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127116 | Episode Reward: 144.929 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127314 | Episode Reward: 128.759 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127506 | Episode Reward: 139.886 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127693 | Episode Reward: 144.024 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127892 | Episode Reward: 134.078 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128088 | Episode Reward: 144.643 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128344 | Episode Reward: 135.309 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128534 | Episode Reward: 140.459 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128717 | Episode Reward: 145.044 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128903 | Episode Reward: 145.923 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129107 | Episode Reward: 135.546 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129293 | Episode Reward: 144.632 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129481 | Episode Reward: 142.156 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129676 | Episode Reward: 138.604 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129905 | Episode Reward: 141.992 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130113 | Episode Reward: 143.975 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130321 | Episode Reward: 144.356 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130516 | Episode Reward: 143.077 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130705 | Episode Reward: 139.656 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130906 | Episode Reward: 134.415 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131109 | Episode Reward: 134.545 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131303 | Episode Reward: 144.401 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131499 | Episode Reward: 142.114 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131688 | Episode Reward: 143.498 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131884 | Episode Reward: 140.567 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132068 | Episode Reward: 143.196 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132294 | Episode Reward: 146.737 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132531 | Episode Reward: 144.909 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132739 | Episode Reward: 142.400 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132929 | Episode Reward: 138.089 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133145 | Episode Reward: 142.376 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133360 | Episode Reward: 130.843 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133554 | Episode Reward: 138.634 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133749 | Episode Reward: 135.060 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133940 | Episode Reward: 139.438 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134133 | Episode Reward: 140.948 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134320 | Episode Reward: 147.580 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134520 | Episode Reward: 135.051 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134723 | Episode Reward: 137.952 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134927 | Episode Reward: 136.637 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135114 | Episode Reward: 145.182 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135325 | Episode Reward: 141.031 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135514 | Episode Reward: 143.728 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135703 | Episode Reward: 138.594 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135891 | Episode Reward: 147.454 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136090 | Episode Reward: 141.298 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136293 | Episode Reward: 148.157 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136532 | Episode Reward: 139.942 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136754 | Episode Reward: 147.477 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136951 | Episode Reward: 140.427 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137154 | Episode Reward: 137.642 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137363 | Episode Reward: 137.873 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137576 | Episode Reward: 130.991 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137761 | Episode Reward: 140.279 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137952 | Episode Reward: 134.453 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138148 | Episode Reward: 142.146 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138343 | Episode Reward: 134.453 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138539 | Episode Reward: 144.640 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138734 | Episode Reward: 138.178 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138929 | Episode Reward: 145.791 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139128 | Episode Reward: 144.326 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139319 | Episode Reward: 145.069 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139522 | Episode Reward: 138.558 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139721 | Episode Reward: 140.395 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139905 | Episode Reward: 123.742 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140098 | Episode Reward: 146.140 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140297 | Episode Reward: 142.934 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140504 | Episode Reward: 146.179 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140712 | Episode Reward: 145.264 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140918 | Episode Reward: 130.381 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141139 | Episode Reward: 139.543 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141349 | Episode Reward: 132.725 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141603 | Episode Reward: 130.639 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141788 | Episode Reward: 131.997 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141981 | Episode Reward: 140.357 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142224 | Episode Reward: 142.735 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142405 | Episode Reward: 143.755 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142594 | Episode Reward: 144.268 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142790 | Episode Reward: 142.209 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142984 | Episode Reward: 143.119 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143171 | Episode Reward: 143.918 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143368 | Episode Reward: 138.041 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143572 | Episode Reward: 132.158 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143777 | Episode Reward: 133.580 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143981 | Episode Reward: 141.759 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144177 | Episode Reward: 140.802 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144374 | Episode Reward: 141.328 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144611 | Episode Reward: 147.368 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144826 | Episode Reward: 134.828 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145026 | Episode Reward: 132.400 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145256 | Episode Reward: 142.737 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145445 | Episode Reward: 122.136 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145638 | Episode Reward: 137.610 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145869 | Episode Reward: 136.771 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146084 | Episode Reward: 136.455 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146273 | Episode Reward: 140.036 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146483 | Episode Reward: 138.183 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146677 | Episode Reward: 139.997 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146871 | Episode Reward: 143.080 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147104 | Episode Reward: 143.917 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147288 | Episode Reward: 147.195 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147477 | Episode Reward: 138.345 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147669 | Episode Reward: 140.017 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147862 | Episode Reward: 140.233 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148056 | Episode Reward: 139.443 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148314 | Episode Reward: 140.179 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148520 | Episode Reward: 138.286 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148711 | Episode Reward: 144.870 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148905 | Episode Reward: 138.666 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149115 | Episode Reward: 141.243 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149311 | Episode Reward: 138.258 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149500 | Episode Reward: 144.302 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149695 | Episode Reward: 131.291 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149900 | Episode Reward: 125.086 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150090 | Episode Reward: 140.454 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150283 | Episode Reward: 146.011 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150491 | Episode Reward: 136.424 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150684 | Episode Reward: 143.416 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150876 | Episode Reward: 142.056 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151071 | Episode Reward: 135.818 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151277 | Episode Reward: 140.626 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151518 | Episode Reward: 133.646 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151717 | Episode Reward: 142.146 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151922 | Episode Reward: 139.873 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152126 | Episode Reward: 138.159 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152311 | Episode Reward: 142.369 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152506 | Episode Reward: 134.841 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152695 | Episode Reward: 142.570 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152890 | Episode Reward: 140.988 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153089 | Episode Reward: 144.591 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153291 | Episode Reward: 136.575 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153493 | Episode Reward: 132.628 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153706 | Episode Reward: 147.171 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153905 | Episode Reward: 140.440 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154096 | Episode Reward: 147.231 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154294 | Episode Reward: 139.331 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154526 | Episode Reward: 149.494 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154728 | Episode Reward: 140.721 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154918 | Episode Reward: 139.720 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155112 | Episode Reward: 139.285 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155298 | Episode Reward: 143.583 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155490 | Episode Reward: 140.646 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155678 | Episode Reward: 147.962 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155877 | Episode Reward: 140.155 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156083 | Episode Reward: 132.268 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156278 | Episode Reward: 143.955 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156473 | Episode Reward: 141.545 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156654 | Episode Reward: 147.781 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156892 | Episode Reward: 147.382 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157090 | Episode Reward: 140.467 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157305 | Episode Reward: 141.594 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157499 | Episode Reward: 141.410 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157681 | Episode Reward: 148.752 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157877 | Episode Reward: 143.138 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158070 | Episode Reward: 145.106 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158266 | Episode Reward: 143.711 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158460 | Episode Reward: 142.462 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158652 | Episode Reward: 138.340 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158849 | Episode Reward: 139.301 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159045 | Episode Reward: 142.788 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159244 | Episode Reward: 144.186 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159440 | Episode Reward: 139.299 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159695 | Episode Reward: 138.971 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159882 | Episode Reward: 139.421 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160073 | Episode Reward: 141.368 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160275 | Episode Reward: 143.110 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160467 | Episode Reward: 135.925 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160721 | Episode Reward: 141.187 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160918 | Episode Reward: 119.266 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161123 | Episode Reward: 139.099 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161323 | Episode Reward: 142.362 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161529 | Episode Reward: 139.755 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161723 | Episode Reward: 140.792 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161932 | Episode Reward: 140.278 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162120 | Episode Reward: 144.173 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162331 | Episode Reward: 140.316 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162526 | Episode Reward: 142.839 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162734 | Episode Reward: 139.097 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162942 | Episode Reward: 127.703 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163154 | Episode Reward: 136.847 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163352 | Episode Reward: 139.753 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163544 | Episode Reward: 141.043 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163755 | Episode Reward: 134.080 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163994 | Episode Reward: 146.796 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164187 | Episode Reward: 145.211 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164371 | Episode Reward: 135.529 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164582 | Episode Reward: 143.716 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164792 | Episode Reward: 143.722 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164977 | Episode Reward: 137.167 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165182 | Episode Reward: 142.734 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165408 | Episode Reward: 144.121 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165616 | Episode Reward: 137.613 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165815 | Episode Reward: 145.556 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166002 | Episode Reward: 144.714 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166212 | Episode Reward: 143.764 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166408 | Episode Reward: 141.227 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166612 | Episode Reward: 141.171 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166807 | Episode Reward: 136.280 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167008 | Episode Reward: 141.748 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167209 | Episode Reward: 143.392 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167407 | Episode Reward: 138.813 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167617 | Episode Reward: 136.757 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167857 | Episode Reward: 144.581 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168091 | Episode Reward: 146.556 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168319 | Episode Reward: 138.045 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168515 | Episode Reward: 138.413 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168710 | Episode Reward: 143.403 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168911 | Episode Reward: 143.268 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169106 | Episode Reward: 140.626 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169307 | Episode Reward: 134.738 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169503 | Episode Reward: 140.215 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169692 | Episode Reward: 135.379 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169899 | Episode Reward: 145.541 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170107 | Episode Reward: 144.892 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170303 | Episode Reward: 138.185 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170495 | Episode Reward: 139.525 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170703 | Episode Reward: 145.336 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170915 | Episode Reward: 136.810 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171121 | Episode Reward: 143.264 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171322 | Episode Reward: 138.451 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171527 | Episode Reward: 136.878 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171780 | Episode Reward: 134.484 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171971 | Episode Reward: 144.088 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172158 | Episode Reward: 138.764 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172347 | Episode Reward: 141.444 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172539 | Episode Reward: 138.147 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172742 | Episode Reward: 133.912 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172941 | Episode Reward: 137.538 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173137 | Episode Reward: 141.363 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173336 | Episode Reward: 142.065 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173538 | Episode Reward: 134.732 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173783 | Episode Reward: 134.955 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173981 | Episode Reward: 121.990 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174173 | Episode Reward: 141.362 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174364 | Episode Reward: 136.969 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174561 | Episode Reward: 145.147 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174805 | Episode Reward: 136.121 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174999 | Episode Reward: 138.631 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175195 | Episode Reward: 139.028 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175389 | Episode Reward: 137.507 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175573 | Episode Reward: 141.565 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175775 | Episode Reward: 144.799 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175962 | Episode Reward: 142.503 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176164 | Episode Reward: 144.926 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176354 | Episode Reward: 144.231 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176547 | Episode Reward: 137.902 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176743 | Episode Reward: 141.217 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176979 | Episode Reward: 136.638 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177187 | Episode Reward: 138.861 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177379 | Episode Reward: 132.041 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177592 | Episode Reward: 142.813 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177799 | Episode Reward: 146.265 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177991 | Episode Reward: 135.455 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178192 | Episode Reward: 137.894 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178381 | Episode Reward: 148.847 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178615 | Episode Reward: 149.124 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178803 | Episode Reward: 139.250 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178995 | Episode Reward: 143.078 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179189 | Episode Reward: 145.371 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179392 | Episode Reward: 139.547 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179594 | Episode Reward: 141.187 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179800 | Episode Reward: 133.948 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180059 | Episode Reward: 131.769 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180260 | Episode Reward: 139.243 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180448 | Episode Reward: 143.626 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180641 | Episode Reward: 137.095 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180829 | Episode Reward: 140.526 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 181062 | Episode Reward: 123.651 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181267 | Episode Reward: 127.843 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181459 | Episode Reward: 142.902 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181649 | Episode Reward: 138.576 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181840 | Episode Reward: 132.889 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182047 | Episode Reward: 143.720 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182283 | Episode Reward: 142.907 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182517 | Episode Reward: 143.787 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182711 | Episode Reward: 137.641 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182925 | Episode Reward: 134.584 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183135 | Episode Reward: 134.769 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183325 | Episode Reward: 136.470 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183517 | Episode Reward: 144.082 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183755 | Episode Reward: 140.692 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183963 | Episode Reward: 138.918 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184160 | Episode Reward: 142.227 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184366 | Episode Reward: 135.491 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184565 | Episode Reward: 138.246 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184752 | Episode Reward: 146.992 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184944 | Episode Reward: 136.726 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185132 | Episode Reward: 140.938 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185326 | Episode Reward: 141.601 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185523 | Episode Reward: 134.666 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185717 | Episode Reward: 142.877 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185920 | Episode Reward: 145.027 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186117 | Episode Reward: 141.148 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186368 | Episode Reward: 143.670 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186570 | Episode Reward: 144.776 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186759 | Episode Reward: 140.761 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186982 | Episode Reward: 129.904 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187172 | Episode Reward: 139.130 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187368 | Episode Reward: 141.528 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187571 | Episode Reward: 126.770 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187773 | Episode Reward: 140.351 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187965 | Episode Reward: 143.798 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188163 | Episode Reward: 143.269 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188358 | Episode Reward: 139.358 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188561 | Episode Reward: 144.688 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188758 | Episode Reward: 119.635 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188949 | Episode Reward: 147.273 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189153 | Episode Reward: 142.596 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189356 | Episode Reward: 134.749 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189602 | Episode Reward: 140.357 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189795 | Episode Reward: 142.631 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189998 | Episode Reward: 141.243 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190203 | Episode Reward: 139.957 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190401 | Episode Reward: 132.895 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190594 | Episode Reward: 137.874 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190785 | Episode Reward: 137.950 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190981 | Episode Reward: 143.989 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191243 | Episode Reward: 134.106 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191444 | Episode Reward: 136.086 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191672 | Episode Reward: 142.494 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191868 | Episode Reward: 133.951 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192069 | Episode Reward: 139.162 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192252 | Episode Reward: 142.899 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192444 | Episode Reward: 138.469 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192649 | Episode Reward: 138.081 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192855 | Episode Reward: 133.772 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193061 | Episode Reward: 136.807 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193267 | Episode Reward: 145.300 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193467 | Episode Reward: 140.809 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193667 | Episode Reward: 138.183 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193866 | Episode Reward: 120.966 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194088 | Episode Reward: 149.754 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194289 | Episode Reward: 137.986 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194495 | Episode Reward: 136.574 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194695 | Episode Reward: 138.719 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194888 | Episode Reward: 144.809 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195090 | Episode Reward: 130.870 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195288 | Episode Reward: 135.792 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195489 | Episode Reward: 142.167 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195722 | Episode Reward: 146.358 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195915 | Episode Reward: 139.548 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196155 | Episode Reward: 136.124 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196341 | Episode Reward: 146.983 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196597 | Episode Reward: 142.946 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196784 | Episode Reward: 138.839 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196979 | Episode Reward: 144.248 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197174 | Episode Reward: 134.508 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197369 | Episode Reward: 138.413 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197563 | Episode Reward: 127.166 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197767 | Episode Reward: 140.048 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197965 | Episode Reward: 146.538 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198167 | Episode Reward: 134.615 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198374 | Episode Reward: 139.344 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198562 | Episode Reward: 144.126 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198762 | Episode Reward: 138.422 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198960 | Episode Reward: 136.007 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199172 | Episode Reward: 131.900 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199358 | Episode Reward: 146.398 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199565 | Episode Reward: 142.470 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199760 | Episode Reward: 142.212 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199955 | Episode Reward: 133.372 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Training finished\n",
      "Saving model to ddqn-sma-no-epsilon-decay.zip\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "ddqn_sma_env = make_env()\n",
    "\n",
    "ddqn_sma_model = Double_DQN_Implementation(\n",
    "    env=ddqn_sma_env, \n",
    "    learning_rate=3e-4, \n",
    "    epsilon_decay_flag = False,\n",
    "    tensorboard_log=\"./wds_custom_logs/\")\n",
    "\n",
    "ddqn_sma_model.learn(total_timesteps=200000)\n",
    "\n",
    "ddqn_sma_model.save(\"ddqn-sma-no-epsilon-decay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf13827-f2ff-4ed4-b1cb-9913e623bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment using EMA\n",
    "base_params['demand_moving_average'] = False  # Turn off SMA \n",
    "base_params['demand_exp_moving_average'] = True  # Turn on EMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae9a328-fc7d-43cb-a4ba-9ba914a73f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200000 steps\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/miniforge3/envs/rl/lib/python3.10/site-packages/gymnasium/spaces/box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/Users/kavish/miniforge3/envs/rl/lib/python3.10/site-packages/gymnasium/spaces/box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 201 | Episode Reward: 140.968 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 415 | Episode Reward: 138.388 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 619 | Episode Reward: 142.308 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 815 | Episode Reward: 140.530 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1020 | Episode Reward: 130.931 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1222 | Episode Reward: 136.340 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1432 | Episode Reward: 139.263 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1639 | Episode Reward: 141.470 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 1844 | Episode Reward: 136.801 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2039 | Episode Reward: 128.545 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2231 | Episode Reward: 139.150 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2436 | Episode Reward: 132.846 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2645 | Episode Reward: 137.831 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 2827 | Episode Reward: 135.624 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3036 | Episode Reward: 129.583 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3256 | Episode Reward: 137.338 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3448 | Episode Reward: 138.419 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3631 | Episode Reward: 144.570 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 3828 | Episode Reward: 141.954 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4034 | Episode Reward: 129.689 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4236 | Episode Reward: 131.617 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4425 | Episode Reward: 142.258 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4622 | Episode Reward: 141.855 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 4814 | Episode Reward: 143.209 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5004 | Episode Reward: 137.042 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5195 | Episode Reward: 146.799 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5401 | Episode Reward: 140.344 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5644 | Episode Reward: 144.097 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 5884 | Episode Reward: 139.093 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6131 | Episode Reward: 144.630 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6318 | Episode Reward: 141.527 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6515 | Episode Reward: 144.218 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6714 | Episode Reward: 135.502 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 6902 | Episode Reward: 142.158 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7103 | Episode Reward: 136.112 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7299 | Episode Reward: 141.305 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7546 | Episode Reward: 140.370 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7741 | Episode Reward: 134.543 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 7927 | Episode Reward: 142.790 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8129 | Episode Reward: 144.594 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8327 | Episode Reward: 139.241 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8522 | Episode Reward: 140.115 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8773 | Episode Reward: 130.725 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 8966 | Episode Reward: 142.523 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9152 | Episode Reward: 142.474 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9347 | Episode Reward: 137.429 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9550 | Episode Reward: 139.349 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9737 | Episode Reward: 146.377 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 9940 | Episode Reward: 137.442 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10155 | Episode Reward: 139.483 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10356 | Episode Reward: 133.231 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10558 | Episode Reward: 136.475 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 10804 | Episode Reward: 130.622 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11000 | Episode Reward: 147.545 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11205 | Episode Reward: 134.354 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11453 | Episode Reward: 138.344 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11641 | Episode Reward: 142.995 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 11868 | Episode Reward: 145.619 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12066 | Episode Reward: 140.926 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12264 | Episode Reward: 136.881 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12461 | Episode Reward: 136.665 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12673 | Episode Reward: 122.927 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 12883 | Episode Reward: 130.227 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13149 | Episode Reward: 129.707 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13380 | Episode Reward: 131.377 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13608 | Episode Reward: 134.064 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13792 | Episode Reward: 146.095 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 13991 | Episode Reward: 142.833 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14197 | Episode Reward: 130.479 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14399 | Episode Reward: 138.125 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14613 | Episode Reward: 137.590 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 14822 | Episode Reward: 143.109 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15018 | Episode Reward: 139.878 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15214 | Episode Reward: 139.274 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15417 | Episode Reward: 140.897 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15603 | Episode Reward: 145.501 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 15817 | Episode Reward: 142.902 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16004 | Episode Reward: 144.061 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16208 | Episode Reward: 119.679 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16412 | Episode Reward: 143.080 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16639 | Episode Reward: 135.121 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 16827 | Episode Reward: 142.934 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17029 | Episode Reward: 139.898 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17237 | Episode Reward: 140.867 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17433 | Episode Reward: 137.317 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17618 | Episode Reward: 143.098 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 17816 | Episode Reward: 142.405 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18017 | Episode Reward: 134.645 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18224 | Episode Reward: 128.178 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18419 | Episode Reward: 140.232 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18610 | Episode Reward: 143.570 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 18808 | Episode Reward: 139.695 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19000 | Episode Reward: 144.877 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19205 | Episode Reward: 139.206 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19408 | Episode Reward: 122.272 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19609 | Episode Reward: 139.846 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 19815 | Episode Reward: 136.233 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20015 | Episode Reward: 135.156 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20220 | Episode Reward: 138.544 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20411 | Episode Reward: 141.841 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20612 | Episode Reward: 120.845 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 20835 | Episode Reward: 140.684 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21038 | Episode Reward: 142.717 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21227 | Episode Reward: 145.482 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21478 | Episode Reward: 137.876 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: System may be hydraulically unstable.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 21736 | Episode Reward: 133.384 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 21945 | Episode Reward: 138.688 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22153 | Episode Reward: 136.877 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22342 | Episode Reward: 144.885 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22540 | Episode Reward: 140.838 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22745 | Episode Reward: 141.895 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 22953 | Episode Reward: 142.828 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23159 | Episode Reward: 140.139 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23364 | Episode Reward: 138.462 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23568 | Episode Reward: 132.635 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 23805 | Episode Reward: 141.880 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24004 | Episode Reward: 137.927 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24210 | Episode Reward: 136.640 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24402 | Episode Reward: 141.754 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24591 | Episode Reward: 145.541 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 24783 | Episode Reward: 143.256 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25017 | Episode Reward: 140.255 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25216 | Episode Reward: 145.642 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25415 | Episode Reward: 135.919 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25613 | Episode Reward: 141.851 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 25809 | Episode Reward: 136.838 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26000 | Episode Reward: 147.906 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26188 | Episode Reward: 144.188 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26423 | Episode Reward: 143.379 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26626 | Episode Reward: 125.446 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 26824 | Episode Reward: 132.003 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27013 | Episode Reward: 142.827 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27204 | Episode Reward: 134.703 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27410 | Episode Reward: 126.789 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27618 | Episode Reward: 145.503 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 27817 | Episode Reward: 143.654 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28010 | Episode Reward: 147.738 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28203 | Episode Reward: 146.912 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28420 | Episode Reward: 139.759 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28600 | Episode Reward: 145.195 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 28844 | Episode Reward: 133.978 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29045 | Episode Reward: 137.729 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29241 | Episode Reward: 142.479 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29440 | Episode Reward: 138.408 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29694 | Episode Reward: 135.971 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 29894 | Episode Reward: 133.788 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30095 | Episode Reward: 136.259 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30282 | Episode Reward: 144.099 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30481 | Episode Reward: 135.861 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30683 | Episode Reward: 141.708 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 30878 | Episode Reward: 139.913 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31107 | Episode Reward: 139.516 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31310 | Episode Reward: 141.311 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31511 | Episode Reward: 133.218 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31724 | Episode Reward: 139.297 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 31915 | Episode Reward: 143.874 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32100 | Episode Reward: 142.226 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32289 | Episode Reward: 143.901 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32507 | Episode Reward: 133.038 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32745 | Episode Reward: 141.831 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 32933 | Episode Reward: 137.135 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33131 | Episode Reward: 144.882 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33327 | Episode Reward: 141.914 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33568 | Episode Reward: 144.187 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33762 | Episode Reward: 136.050 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 33960 | Episode Reward: 141.695 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34198 | Episode Reward: 143.425 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34392 | Episode Reward: 140.966 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34596 | Episode Reward: 136.040 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34792 | Episode Reward: 124.934 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 34979 | Episode Reward: 143.604 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35172 | Episode Reward: 135.860 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35356 | Episode Reward: 139.939 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35559 | Episode Reward: 133.535 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35745 | Episode Reward: 144.718 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 35954 | Episode Reward: 134.782 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36146 | Episode Reward: 136.246 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36345 | Episode Reward: 140.864 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36535 | Episode Reward: 144.338 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36723 | Episode Reward: 139.010 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 36921 | Episode Reward: 144.463 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37120 | Episode Reward: 137.845 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37367 | Episode Reward: 144.487 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37561 | Episode Reward: 122.334 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37767 | Episode Reward: 143.537 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 37971 | Episode Reward: 138.543 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38176 | Episode Reward: 143.931 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38367 | Episode Reward: 141.316 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38578 | Episode Reward: 136.416 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38770 | Episode Reward: 141.590 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 38973 | Episode Reward: 143.918 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39163 | Episode Reward: 133.902 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39369 | Episode Reward: 141.193 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39567 | Episode Reward: 121.003 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 39827 | Episode Reward: 124.717 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40033 | Episode Reward: 136.578 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40237 | Episode Reward: 131.728 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40434 | Episode Reward: 139.431 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40632 | Episode Reward: 138.303 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 40823 | Episode Reward: 138.172 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41023 | Episode Reward: 143.771 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41295 | Episode Reward: 123.387 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41499 | Episode Reward: 142.156 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41698 | Episode Reward: 144.922 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 41888 | Episode Reward: 121.306 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42084 | Episode Reward: 136.384 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42291 | Episode Reward: 133.524 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42527 | Episode Reward: 141.852 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42715 | Episode Reward: 143.026 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 42921 | Episode Reward: 147.580 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43121 | Episode Reward: 137.155 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43321 | Episode Reward: 141.769 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43527 | Episode Reward: 144.960 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43724 | Episode Reward: 140.220 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 43913 | Episode Reward: 144.625 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44169 | Episode Reward: 134.414 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44369 | Episode Reward: 133.698 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44562 | Episode Reward: 146.690 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 44805 | Episode Reward: 144.021 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45005 | Episode Reward: 141.612 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45207 | Episode Reward: 140.455 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45402 | Episode Reward: 141.285 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45655 | Episode Reward: 144.097 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 45859 | Episode Reward: 130.212 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46051 | Episode Reward: 143.188 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46245 | Episode Reward: 122.925 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46443 | Episode Reward: 145.999 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46633 | Episode Reward: 142.392 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 46851 | Episode Reward: 135.132 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47051 | Episode Reward: 142.352 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47266 | Episode Reward: 138.463 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47464 | Episode Reward: 146.091 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47663 | Episode Reward: 140.970 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 47864 | Episode Reward: 141.319 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48079 | Episode Reward: 140.037 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48296 | Episode Reward: 128.268 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48482 | Episode Reward: 143.669 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48693 | Episode Reward: 136.923 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 48878 | Episode Reward: 141.413 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49069 | Episode Reward: 142.368 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49266 | Episode Reward: 137.203 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49462 | Episode Reward: 138.182 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49705 | Episode Reward: 136.511 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 49905 | Episode Reward: 139.609 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50092 | Episode Reward: 144.386 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50276 | Episode Reward: 145.445 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50478 | Episode Reward: 144.523 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50670 | Episode Reward: 139.033 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 50870 | Episode Reward: 134.668 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51075 | Episode Reward: 138.005 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51275 | Episode Reward: 127.425 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51509 | Episode Reward: 143.008 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51716 | Episode Reward: 139.702 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 51909 | Episode Reward: 143.027 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52102 | Episode Reward: 139.433 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52345 | Episode Reward: 136.251 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52545 | Episode Reward: 142.462 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52738 | Episode Reward: 142.519 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 52937 | Episode Reward: 135.805 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53143 | Episode Reward: 133.263 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53349 | Episode Reward: 139.017 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53543 | Episode Reward: 135.255 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53736 | Episode Reward: 141.065 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 53936 | Episode Reward: 142.291 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54121 | Episode Reward: 143.947 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54303 | Episode Reward: 142.400 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54502 | Episode Reward: 139.344 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54697 | Episode Reward: 147.509 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 54886 | Episode Reward: 135.567 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55083 | Episode Reward: 142.027 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55278 | Episode Reward: 140.313 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55471 | Episode Reward: 144.364 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55682 | Episode Reward: 135.696 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 55867 | Episode Reward: 143.699 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56100 | Episode Reward: 146.840 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56311 | Episode Reward: 142.788 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56570 | Episode Reward: 127.120 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56769 | Episode Reward: 138.198 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 56960 | Episode Reward: 141.383 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57189 | Episode Reward: 139.657 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57389 | Episode Reward: 135.851 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57588 | Episode Reward: 126.237 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57780 | Episode Reward: 138.377 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 57969 | Episode Reward: 148.233 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58166 | Episode Reward: 142.090 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58360 | Episode Reward: 141.736 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58559 | Episode Reward: 139.405 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58752 | Episode Reward: 133.930 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 58958 | Episode Reward: 142.930 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: System may be hydraulically unstable.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 59202 | Episode Reward: 137.571 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59405 | Episode Reward: 140.480 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59607 | Episode Reward: 134.172 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 59829 | Episode Reward: 138.324 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60081 | Episode Reward: 138.620 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60294 | Episode Reward: 144.108 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60487 | Episode Reward: 140.921 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60748 | Episode Reward: 137.595 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 60941 | Episode Reward: 143.406 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61135 | Episode Reward: 140.910 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61386 | Episode Reward: 140.432 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61582 | Episode Reward: 140.195 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61783 | Episode Reward: 129.527 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 61975 | Episode Reward: 143.811 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62197 | Episode Reward: 147.306 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62388 | Episode Reward: 141.003 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62584 | Episode Reward: 142.154 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62782 | Episode Reward: 133.467 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 62977 | Episode Reward: 134.336 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 63188 | Episode Reward: 135.637 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 63383 | Episode Reward: 137.883 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 63642 | Episode Reward: 126.417 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 63862 | Episode Reward: 143.774 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64050 | Episode Reward: 142.111 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64267 | Episode Reward: 135.848 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64473 | Episode Reward: 137.467 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64668 | Episode Reward: 141.640 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 64870 | Episode Reward: 134.792 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65063 | Episode Reward: 140.721 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65257 | Episode Reward: 134.826 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65469 | Episode Reward: 140.429 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65675 | Episode Reward: 141.404 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 65914 | Episode Reward: 125.828 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66152 | Episode Reward: 136.153 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66353 | Episode Reward: 143.372 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66544 | Episode Reward: 143.025 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66749 | Episode Reward: 138.682 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 66947 | Episode Reward: 137.989 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67127 | Episode Reward: 142.735 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67323 | Episode Reward: 140.510 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67527 | Episode Reward: 138.447 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67726 | Episode Reward: 141.767 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 67949 | Episode Reward: 143.405 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 68185 | Episode Reward: 127.535 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68387 | Episode Reward: 143.239 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68590 | Episode Reward: 143.119 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68791 | Episode Reward: 142.126 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 68988 | Episode Reward: 135.324 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69235 | Episode Reward: 146.936 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69432 | Episode Reward: 142.640 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69641 | Episode Reward: 143.518 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 69890 | Episode Reward: 130.738 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70091 | Episode Reward: 135.014 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70293 | Episode Reward: 138.110 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70497 | Episode Reward: 139.748 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70728 | Episode Reward: 143.113 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 70929 | Episode Reward: 143.798 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71129 | Episode Reward: 138.806 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71325 | Episode Reward: 141.445 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71517 | Episode Reward: 143.126 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71717 | Episode Reward: 135.606 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 71904 | Episode Reward: 146.904 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72100 | Episode Reward: 138.673 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 72350 | Episode Reward: 128.239 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72552 | Episode Reward: 137.930 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72739 | Episode Reward: 141.305 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 72930 | Episode Reward: 147.410 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73130 | Episode Reward: 146.927 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73312 | Episode Reward: 144.885 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 73570 | Episode Reward: 135.606 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73765 | Episode Reward: 147.254 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 73958 | Episode Reward: 142.827 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74150 | Episode Reward: 143.154 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74407 | Episode Reward: 124.998 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74613 | Episode Reward: 137.822 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74804 | Episode Reward: 144.222 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 74995 | Episode Reward: 145.445 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75197 | Episode Reward: 134.444 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75405 | Episode Reward: 136.902 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75607 | Episode Reward: 132.881 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75789 | Episode Reward: 146.902 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 75982 | Episode Reward: 136.819 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76184 | Episode Reward: 141.541 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76436 | Episode Reward: 143.262 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76632 | Episode Reward: 141.107 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 76822 | Episode Reward: 136.750 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77011 | Episode Reward: 126.819 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77213 | Episode Reward: 139.599 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77416 | Episode Reward: 138.397 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77604 | Episode Reward: 140.587 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77798 | Episode Reward: 139.552 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 77990 | Episode Reward: 137.754 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78197 | Episode Reward: 133.632 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78419 | Episode Reward: 135.683 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78623 | Episode Reward: 144.371 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 78832 | Episode Reward: 142.136 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79031 | Episode Reward: 143.491 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79221 | Episode Reward: 133.248 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79422 | Episode Reward: 139.041 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79627 | Episode Reward: 130.726 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 79833 | Episode Reward: 140.188 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80031 | Episode Reward: 140.678 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80231 | Episode Reward: 143.331 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80467 | Episode Reward: 144.478 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80654 | Episode Reward: 139.487 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 80856 | Episode Reward: 132.579 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81087 | Episode Reward: 147.378 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81277 | Episode Reward: 141.601 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81475 | Episode Reward: 145.670 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81671 | Episode Reward: 137.228 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 81872 | Episode Reward: 143.208 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82066 | Episode Reward: 136.487 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82255 | Episode Reward: 140.792 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82463 | Episode Reward: 134.883 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82655 | Episode Reward: 141.685 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 82857 | Episode Reward: 136.732 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83056 | Episode Reward: 142.841 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83256 | Episode Reward: 130.754 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83455 | Episode Reward: 133.202 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83651 | Episode Reward: 145.787 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 83859 | Episode Reward: 133.528 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84048 | Episode Reward: 127.064 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84243 | Episode Reward: 129.515 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84439 | Episode Reward: 139.453 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84672 | Episode Reward: 144.933 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 84869 | Episode Reward: 139.135 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85067 | Episode Reward: 135.503 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85263 | Episode Reward: 140.520 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85456 | Episode Reward: 137.404 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85657 | Episode Reward: 144.161 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 85865 | Episode Reward: 137.196 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86058 | Episode Reward: 138.571 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86253 | Episode Reward: 149.037 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86444 | Episode Reward: 140.682 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86641 | Episode Reward: 137.815 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 86841 | Episode Reward: 135.873 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87025 | Episode Reward: 146.126 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87215 | Episode Reward: 143.193 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87411 | Episode Reward: 133.093 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87603 | Episode Reward: 141.738 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 87807 | Episode Reward: 132.258 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88005 | Episode Reward: 131.081 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88193 | Episode Reward: 144.146 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88395 | Episode Reward: 135.492 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88599 | Episode Reward: 139.289 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 88789 | Episode Reward: 139.408 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89003 | Episode Reward: 138.445 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89202 | Episode Reward: 141.098 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89389 | Episode Reward: 140.958 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89622 | Episode Reward: 145.669 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 89845 | Episode Reward: 144.617 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90041 | Episode Reward: 135.312 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90233 | Episode Reward: 135.206 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90430 | Episode Reward: 132.347 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90620 | Episode Reward: 142.714 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 90808 | Episode Reward: 141.471 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91017 | Episode Reward: 135.567 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91209 | Episode Reward: 139.128 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91412 | Episode Reward: 134.138 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91594 | Episode Reward: 142.215 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 91797 | Episode Reward: 142.298 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92001 | Episode Reward: 143.951 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92195 | Episode Reward: 143.267 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92442 | Episode Reward: 144.118 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92656 | Episode Reward: 136.024 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 92851 | Episode Reward: 136.681 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93050 | Episode Reward: 129.474 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93246 | Episode Reward: 133.064 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93439 | Episode Reward: 142.370 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93642 | Episode Reward: 146.329 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 93882 | Episode Reward: 140.333 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94067 | Episode Reward: 125.323 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94259 | Episode Reward: 137.016 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94462 | Episode Reward: 134.337 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94664 | Episode Reward: 143.930 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 94862 | Episode Reward: 139.877 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95081 | Episode Reward: 134.551 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95285 | Episode Reward: 142.845 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95482 | Episode Reward: 138.497 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95671 | Episode Reward: 139.881 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 95916 | Episode Reward: 137.107 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96113 | Episode Reward: 123.275 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96321 | Episode Reward: 130.128 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96523 | Episode Reward: 137.461 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96729 | Episode Reward: 138.397 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 96914 | Episode Reward: 138.839 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97104 | Episode Reward: 142.388 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97300 | Episode Reward: 136.597 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97518 | Episode Reward: 148.436 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97714 | Episode Reward: 142.653 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 97918 | Episode Reward: 141.367 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98146 | Episode Reward: 140.855 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98340 | Episode Reward: 141.701 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98545 | Episode Reward: 139.727 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98752 | Episode Reward: 138.493 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 98950 | Episode Reward: 134.151 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99154 | Episode Reward: 133.687 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99344 | Episode Reward: 143.443 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99545 | Episode Reward: 138.615 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99745 | Episode Reward: 143.356 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 99943 | Episode Reward: 136.200 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100173 | Episode Reward: 143.302 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100372 | Episode Reward: 140.580 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100574 | Episode Reward: 137.527 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100770 | Episode Reward: 139.890 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 100976 | Episode Reward: 140.500 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101229 | Episode Reward: 147.414 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101417 | Episode Reward: 138.597 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101621 | Episode Reward: 137.134 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 101821 | Episode Reward: 142.751 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102025 | Episode Reward: 137.247 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102228 | Episode Reward: 143.819 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102410 | Episode Reward: 142.751 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102607 | Episode Reward: 124.770 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 102808 | Episode Reward: 137.268 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103005 | Episode Reward: 140.263 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103200 | Episode Reward: 137.390 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103398 | Episode Reward: 139.402 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103600 | Episode Reward: 137.452 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 103822 | Episode Reward: 142.716 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104009 | Episode Reward: 141.787 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104204 | Episode Reward: 140.925 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104397 | Episode Reward: 133.307 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104585 | Episode Reward: 122.699 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 104775 | Episode Reward: 144.156 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105009 | Episode Reward: 143.098 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105215 | Episode Reward: 144.193 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105419 | Episode Reward: 135.395 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105616 | Episode Reward: 141.989 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105808 | Episode Reward: 139.591 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 105993 | Episode Reward: 145.576 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106188 | Episode Reward: 140.342 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106386 | Episode Reward: 136.947 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106594 | Episode Reward: 139.688 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106788 | Episode Reward: 136.884 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 106978 | Episode Reward: 143.621 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107177 | Episode Reward: 142.764 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107368 | Episode Reward: 144.036 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107553 | Episode Reward: 143.337 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 107769 | Episode Reward: 139.276 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108007 | Episode Reward: 139.198 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108188 | Episode Reward: 144.225 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108387 | Episode Reward: 143.965 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108583 | Episode Reward: 140.723 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 108789 | Episode Reward: 139.861 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109001 | Episode Reward: 133.390 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 109192 | Episode Reward: 133.900 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109391 | Episode Reward: 142.768 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109596 | Episode Reward: 145.480 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 109787 | Episode Reward: 142.448 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110039 | Episode Reward: 126.968 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 110292 | Episode Reward: 127.189 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110477 | Episode Reward: 138.993 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110680 | Episode Reward: 132.417 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 110877 | Episode Reward: 141.513 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111067 | Episode Reward: 145.493 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111262 | Episode Reward: 139.717 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111496 | Episode Reward: 135.581 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111707 | Episode Reward: 138.388 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 111925 | Episode Reward: 134.811 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112127 | Episode Reward: 135.570 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112328 | Episode Reward: 140.464 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112514 | Episode Reward: 135.873 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112721 | Episode Reward: 138.438 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 112911 | Episode Reward: 135.761 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113114 | Episode Reward: 137.906 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113320 | Episode Reward: 141.396 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113519 | Episode Reward: 142.325 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113715 | Episode Reward: 136.078 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 113914 | Episode Reward: 140.334 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114158 | Episode Reward: 136.539 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114350 | Episode Reward: 144.327 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114536 | Episode Reward: 138.532 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114733 | Episode Reward: 139.717 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 114938 | Episode Reward: 132.649 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115139 | Episode Reward: 140.262 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115330 | Episode Reward: 143.013 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115518 | Episode Reward: 140.699 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115735 | Episode Reward: 138.223 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 115935 | Episode Reward: 136.017 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116133 | Episode Reward: 145.984 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116335 | Episode Reward: 140.428 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116528 | Episode Reward: 143.653 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116715 | Episode Reward: 139.411 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 116915 | Episode Reward: 141.207 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117131 | Episode Reward: 134.234 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117336 | Episode Reward: 145.353 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117521 | Episode Reward: 140.319 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117717 | Episode Reward: 146.781 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 117903 | Episode Reward: 146.120 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118105 | Episode Reward: 139.123 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118306 | Episode Reward: 138.066 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118500 | Episode Reward: 134.612 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118684 | Episode Reward: 142.083 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 118881 | Episode Reward: 144.623 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119109 | Episode Reward: 135.705 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119305 | Episode Reward: 136.141 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119500 | Episode Reward: 141.598 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119694 | Episode Reward: 144.638 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 119928 | Episode Reward: 131.817 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120116 | Episode Reward: 135.503 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120316 | Episode Reward: 142.876 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120514 | Episode Reward: 135.875 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120703 | Episode Reward: 138.818 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 120914 | Episode Reward: 146.066 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121105 | Episode Reward: 145.302 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121333 | Episode Reward: 140.415 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121525 | Episode Reward: 142.982 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121723 | Episode Reward: 144.228 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 121919 | Episode Reward: 141.049 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122113 | Episode Reward: 134.812 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122294 | Episode Reward: 143.354 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122491 | Episode Reward: 142.452 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122725 | Episode Reward: 138.197 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 122913 | Episode Reward: 140.610 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123122 | Episode Reward: 134.734 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123334 | Episode Reward: 143.867 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123533 | Episode Reward: 130.409 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123725 | Episode Reward: 141.442 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 123930 | Episode Reward: 136.494 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124128 | Episode Reward: 136.060 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124329 | Episode Reward: 145.561 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124526 | Episode Reward: 139.149 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124729 | Episode Reward: 141.728 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 124945 | Episode Reward: 137.731 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125160 | Episode Reward: 144.289 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125367 | Episode Reward: 136.959 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125572 | Episode Reward: 139.764 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125761 | Episode Reward: 141.613 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 125959 | Episode Reward: 141.722 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126173 | Episode Reward: 132.124 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126375 | Episode Reward: 137.964 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126579 | Episode Reward: 134.846 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126772 | Episode Reward: 143.942 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 126971 | Episode Reward: 144.932 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127166 | Episode Reward: 142.221 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127376 | Episode Reward: 143.512 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127571 | Episode Reward: 131.549 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127777 | Episode Reward: 136.277 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 127972 | Episode Reward: 140.682 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128190 | Episode Reward: 131.751 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128384 | Episode Reward: 142.586 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128638 | Episode Reward: 136.101 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 128832 | Episode Reward: 138.544 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129025 | Episode Reward: 141.205 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129224 | Episode Reward: 144.251 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129430 | Episode Reward: 139.415 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129626 | Episode Reward: 142.514 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 129821 | Episode Reward: 138.268 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130022 | Episode Reward: 136.845 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130267 | Episode Reward: 142.844 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130462 | Episode Reward: 145.139 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130669 | Episode Reward: 146.236 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 130853 | Episode Reward: 143.650 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131044 | Episode Reward: 138.815 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131236 | Episode Reward: 139.026 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131434 | Episode Reward: 133.883 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131631 | Episode Reward: 145.058 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 131837 | Episode Reward: 139.394 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132036 | Episode Reward: 141.246 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132234 | Episode Reward: 139.662 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132425 | Episode Reward: 142.500 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132646 | Episode Reward: 144.210 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 132872 | Episode Reward: 146.186 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133076 | Episode Reward: 140.001 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133278 | Episode Reward: 138.013 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133473 | Episode Reward: 146.541 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133685 | Episode Reward: 130.928 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 133877 | Episode Reward: 137.587 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134069 | Episode Reward: 139.899 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134267 | Episode Reward: 136.630 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134479 | Episode Reward: 138.772 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134672 | Episode Reward: 148.113 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 134879 | Episode Reward: 133.355 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135073 | Episode Reward: 138.339 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135274 | Episode Reward: 135.447 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135477 | Episode Reward: 142.527 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135699 | Episode Reward: 140.342 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 135881 | Episode Reward: 144.347 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136067 | Episode Reward: 136.925 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136265 | Episode Reward: 145.498 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136469 | Episode Reward: 141.715 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136667 | Episode Reward: 145.801 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 136915 | Episode Reward: 134.721 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137151 | Episode Reward: 145.077 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137359 | Episode Reward: 138.043 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137564 | Episode Reward: 137.158 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137769 | Episode Reward: 143.025 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 137972 | Episode Reward: 135.081 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138173 | Episode Reward: 138.491 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138366 | Episode Reward: 135.395 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138570 | Episode Reward: 141.077 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 138763 | Episode Reward: 133.260 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 138965 | Episode Reward: 143.864 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139160 | Episode Reward: 137.477 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139350 | Episode Reward: 144.603 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139547 | Episode Reward: 143.638 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139736 | Episode Reward: 142.970 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 139930 | Episode Reward: 142.919 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140115 | Episode Reward: 142.329 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140300 | Episode Reward: 119.534 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140490 | Episode Reward: 146.493 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140690 | Episode Reward: 140.519 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 140890 | Episode Reward: 145.439 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141093 | Episode Reward: 145.024 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 141299 | Episode Reward: 128.665 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141534 | Episode Reward: 134.260 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 141758 | Episode Reward: 132.790 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142018 | Episode Reward: 131.472 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142217 | Episode Reward: 132.917 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142422 | Episode Reward: 137.027 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142670 | Episode Reward: 139.719 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 142862 | Episode Reward: 139.745 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143050 | Episode Reward: 143.400 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143257 | Episode Reward: 141.543 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143464 | Episode Reward: 139.289 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143655 | Episode Reward: 144.536 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 143851 | Episode Reward: 138.851 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144038 | Episode Reward: 134.635 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144237 | Episode Reward: 135.156 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144448 | Episode Reward: 138.330 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144639 | Episode Reward: 143.588 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 144835 | Episode Reward: 140.688 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145073 | Episode Reward: 147.752 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145275 | Episode Reward: 135.532 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145479 | Episode Reward: 133.953 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145732 | Episode Reward: 140.777 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 145918 | Episode Reward: 126.258 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146111 | Episode Reward: 140.089 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146327 | Episode Reward: 140.470 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146546 | Episode Reward: 137.955 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146735 | Episode Reward: 142.950 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 146934 | Episode Reward: 139.734 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147137 | Episode Reward: 139.579 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147320 | Episode Reward: 144.118 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147554 | Episode Reward: 145.121 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147764 | Episode Reward: 144.227 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 147941 | Episode Reward: 138.495 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148127 | Episode Reward: 139.089 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148326 | Episode Reward: 136.728 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148531 | Episode Reward: 135.535 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148770 | Episode Reward: 143.287 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 148965 | Episode Reward: 138.514 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149174 | Episode Reward: 140.300 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149371 | Episode Reward: 136.135 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149578 | Episode Reward: 139.533 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149764 | Episode Reward: 139.199 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 149954 | Episode Reward: 143.468 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150157 | Episode Reward: 133.927 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150358 | Episode Reward: 129.678 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150563 | Episode Reward: 139.785 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150757 | Episode Reward: 140.690 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 150966 | Episode Reward: 138.747 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151159 | Episode Reward: 143.755 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151365 | Episode Reward: 142.058 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151564 | Episode Reward: 136.047 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151766 | Episode Reward: 142.395 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 151999 | Episode Reward: 137.868 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152202 | Episode Reward: 141.979 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152397 | Episode Reward: 142.960 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152594 | Episode Reward: 136.218 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152781 | Episode Reward: 142.808 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 152985 | Episode Reward: 134.070 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153192 | Episode Reward: 142.094 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153383 | Episode Reward: 141.038 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153584 | Episode Reward: 144.011 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153775 | Episode Reward: 138.478 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 153968 | Episode Reward: 135.516 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154175 | Episode Reward: 145.046 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154367 | Episode Reward: 141.015 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154555 | Episode Reward: 143.402 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154753 | Episode Reward: 139.936 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 154987 | Episode Reward: 147.864 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155186 | Episode Reward: 141.690 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155370 | Episode Reward: 141.622 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155574 | Episode Reward: 138.164 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155756 | Episode Reward: 142.874 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 155963 | Episode Reward: 136.729 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156153 | Episode Reward: 147.545 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156353 | Episode Reward: 141.209 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156554 | Episode Reward: 124.795 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156739 | Episode Reward: 146.094 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 156940 | Episode Reward: 139.684 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157140 | Episode Reward: 144.010 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157382 | Episode Reward: 148.742 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157579 | Episode Reward: 141.865 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157792 | Episode Reward: 144.987 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 157999 | Episode Reward: 138.058 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158202 | Episode Reward: 145.028 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158395 | Episode Reward: 142.034 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158592 | Episode Reward: 145.346 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158786 | Episode Reward: 144.394 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 158980 | Episode Reward: 140.757 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159164 | Episode Reward: 138.912 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159365 | Episode Reward: 139.478 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159560 | Episode Reward: 141.258 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159769 | Episode Reward: 144.794 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 159986 | Episode Reward: 133.547 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160229 | Episode Reward: 139.001 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160414 | Episode Reward: 138.786 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160610 | Episode Reward: 140.825 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160797 | Episode Reward: 143.617 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 160994 | Episode Reward: 136.545 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161227 | Episode Reward: 145.753 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161417 | Episode Reward: 120.312 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161610 | Episode Reward: 137.360 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 161821 | Episode Reward: 141.240 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162009 | Episode Reward: 140.859 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162209 | Episode Reward: 141.859 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162407 | Episode Reward: 141.246 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162610 | Episode Reward: 140.493 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162806 | Episode Reward: 138.277 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 162987 | Episode Reward: 141.773 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163196 | Episode Reward: 139.441 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163399 | Episode Reward: 123.579 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163600 | Episode Reward: 144.853 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 163806 | Episode Reward: 137.162 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164001 | Episode Reward: 144.263 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164195 | Episode Reward: 138.017 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164453 | Episode Reward: 143.081 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164649 | Episode Reward: 143.455 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 164857 | Episode Reward: 132.337 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165060 | Episode Reward: 145.253 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165275 | Episode Reward: 142.420 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165472 | Episode Reward: 138.644 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165685 | Episode Reward: 144.211 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 165913 | Episode Reward: 144.521 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166113 | Episode Reward: 139.030 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166309 | Episode Reward: 143.174 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166490 | Episode Reward: 144.488 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166690 | Episode Reward: 144.125 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 166877 | Episode Reward: 140.418 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167082 | Episode Reward: 139.965 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167278 | Episode Reward: 137.728 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167486 | Episode Reward: 139.155 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167673 | Episode Reward: 146.001 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 167880 | Episode Reward: 136.785 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168086 | Episode Reward: 143.879 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168312 | Episode Reward: 145.521 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168542 | Episode Reward: 147.506 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168779 | Episode Reward: 134.227 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 168977 | Episode Reward: 137.415 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169168 | Episode Reward: 143.456 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169361 | Episode Reward: 143.897 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169543 | Episode Reward: 140.593 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169735 | Episode Reward: 136.054 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 169930 | Episode Reward: 140.977 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170138 | Episode Reward: 132.289 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170344 | Episode Reward: 146.204 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170549 | Episode Reward: 144.730 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170746 | Episode Reward: 140.181 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 170944 | Episode Reward: 137.958 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171139 | Episode Reward: 147.539 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171332 | Episode Reward: 137.805 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171539 | Episode Reward: 141.446 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171736 | Episode Reward: 140.242 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 171929 | Episode Reward: 140.116 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172186 | Episode Reward: 134.256 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172374 | Episode Reward: 145.696 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172569 | Episode Reward: 136.377 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172761 | Episode Reward: 140.428 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 172952 | Episode Reward: 138.832 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173155 | Episode Reward: 134.331 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173353 | Episode Reward: 135.650 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173545 | Episode Reward: 143.765 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173735 | Episode Reward: 144.739 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 173925 | Episode Reward: 136.516 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174176 | Episode Reward: 135.514 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174370 | Episode Reward: 126.257 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174556 | Episode Reward: 140.989 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174752 | Episode Reward: 135.368 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 174942 | Episode Reward: 147.361 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175184 | Episode Reward: 135.853 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175386 | Episode Reward: 134.463 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175572 | Episode Reward: 139.912 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175762 | Episode Reward: 137.556 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 175949 | Episode Reward: 143.850 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176159 | Episode Reward: 143.186 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176351 | Episode Reward: 143.295 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176558 | Episode Reward: 145.320 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176749 | Episode Reward: 145.701 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 176938 | Episode Reward: 138.473 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177125 | Episode Reward: 144.309 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177366 | Episode Reward: 135.416 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177570 | Episode Reward: 135.348 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177759 | Episode Reward: 131.632 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 177967 | Episode Reward: 141.637 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178168 | Episode Reward: 142.624 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178363 | Episode Reward: 140.660 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178567 | Episode Reward: 137.112 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 178778 | Episode Reward: 144.245 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179023 | Episode Reward: 145.271 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179211 | Episode Reward: 139.213 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179404 | Episode Reward: 144.068 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179622 | Episode Reward: 140.113 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 179823 | Episode Reward: 140.199 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180021 | Episode Reward: 140.647 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180222 | Episode Reward: 136.897 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 180462 | Episode Reward: 137.140 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180660 | Episode Reward: 141.347 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 180850 | Episode Reward: 141.754 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181042 | Episode Reward: 136.672 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181225 | Episode Reward: 141.284 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181462 | Episode Reward: 120.003 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181669 | Episode Reward: 127.386 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 181856 | Episode Reward: 143.809 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182056 | Episode Reward: 139.577 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182259 | Episode Reward: 130.185 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182470 | Episode Reward: 144.784 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182709 | Episode Reward: 140.310 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 182951 | Episode Reward: 141.008 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183163 | Episode Reward: 135.528 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183370 | Episode Reward: 140.262 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183558 | Episode Reward: 136.399 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183747 | Episode Reward: 136.516 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 183931 | Episode Reward: 144.712 | Epsilon: 1.000\n",
      "Resetting the environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavish/Documents/gym4real/gym4real/envs/wds/simulator/epynet/epanet2.py:683: UserWarning: WARNING: Pumps cannot deliver enough flow or head.\n",
      "  warnings.warn(self.ENgeterror(ierr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 184181 | Episode Reward: 135.208 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184389 | Episode Reward: 140.040 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184589 | Episode Reward: 140.343 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184779 | Episode Reward: 135.000 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 184971 | Episode Reward: 139.094 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185166 | Episode Reward: 147.443 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185360 | Episode Reward: 136.935 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185551 | Episode Reward: 139.646 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185753 | Episode Reward: 141.278 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 185947 | Episode Reward: 137.270 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186145 | Episode Reward: 143.264 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186339 | Episode Reward: 146.224 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186537 | Episode Reward: 141.551 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186789 | Episode Reward: 145.252 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 186983 | Episode Reward: 146.228 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187177 | Episode Reward: 140.223 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187396 | Episode Reward: 132.541 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187587 | Episode Reward: 139.971 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187781 | Episode Reward: 141.229 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 187987 | Episode Reward: 125.931 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188181 | Episode Reward: 142.800 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188386 | Episode Reward: 143.379 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188578 | Episode Reward: 144.938 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188770 | Episode Reward: 137.649 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 188962 | Episode Reward: 145.723 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189158 | Episode Reward: 126.471 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189349 | Episode Reward: 147.167 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189563 | Episode Reward: 141.907 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 189770 | Episode Reward: 135.869 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190013 | Episode Reward: 142.563 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190199 | Episode Reward: 142.448 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190401 | Episode Reward: 142.619 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190593 | Episode Reward: 139.524 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190786 | Episode Reward: 134.837 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 190970 | Episode Reward: 140.478 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191174 | Episode Reward: 136.552 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191367 | Episode Reward: 145.180 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191606 | Episode Reward: 137.921 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 191809 | Episode Reward: 137.000 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192041 | Episode Reward: 142.896 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192241 | Episode Reward: 133.690 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192439 | Episode Reward: 141.103 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192618 | Episode Reward: 142.610 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 192819 | Episode Reward: 138.337 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193020 | Episode Reward: 140.131 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193219 | Episode Reward: 137.422 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193426 | Episode Reward: 136.565 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193609 | Episode Reward: 146.985 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193808 | Episode Reward: 139.558 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 193996 | Episode Reward: 140.578 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194189 | Episode Reward: 129.373 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194430 | Episode Reward: 146.109 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194643 | Episode Reward: 135.111 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 194836 | Episode Reward: 136.135 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195048 | Episode Reward: 132.840 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195247 | Episode Reward: 142.976 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195447 | Episode Reward: 133.825 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195632 | Episode Reward: 140.946 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 195831 | Episode Reward: 141.370 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196065 | Episode Reward: 145.601 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196263 | Episode Reward: 141.187 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196507 | Episode Reward: 137.770 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196699 | Episode Reward: 144.834 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 196934 | Episode Reward: 146.429 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197138 | Episode Reward: 135.062 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197332 | Episode Reward: 142.692 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197529 | Episode Reward: 135.709 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197720 | Episode Reward: 140.432 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 197920 | Episode Reward: 123.536 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198123 | Episode Reward: 140.384 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198324 | Episode Reward: 145.166 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198521 | Episode Reward: 134.867 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198720 | Episode Reward: 144.415 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 198917 | Episode Reward: 143.872 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199113 | Episode Reward: 141.063 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199315 | Episode Reward: 136.427 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199512 | Episode Reward: 136.301 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199701 | Episode Reward: 146.378 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Step: 199908 | Episode Reward: 142.038 | Epsilon: 1.000\n",
      "Resetting the environment...\n",
      "Training finished\n",
      "Saving model to ddqn-ema-no-epsilon-decay.zip\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "ddqn_ema_env = make_env()\n",
    "\n",
    "ddqn_ema_model = Double_DQN_Implementation(\n",
    "    env=ddqn_ema_env, \n",
    "    learning_rate=3e-4, \n",
    "    epsilon_decay_flag = False,\n",
    "    tensorboard_log=\"./wds_custom_logs/\")\n",
    "\n",
    "ddqn_ema_model.learn(total_timesteps=200000)\n",
    "\n",
    "ddqn_ema_model.save(\"ddqn-ema-no-epsilon-decay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
